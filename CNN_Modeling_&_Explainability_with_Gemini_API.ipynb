{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Building a CNN Model with PyTorch"
      ],
      "metadata": {
        "id": "TEuy4EfibT3q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fj-kPNpyX1u1"
      },
      "outputs": [],
      "source": [
        "#Load Required Libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load and Preprocess Data\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "shuffle=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzf3peD1YPpj",
        "outputId": "87abf0ad-50b7-45c2-8ba1-fd0c02a24702"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 488kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.68MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the CNN Model\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1,\n",
        "    padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1,\n",
        "    padding=1)\n",
        "    self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "  def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))\n",
        "    x = self.pool(torch.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 64 * 7 * 7)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "iyYcYyHGZG2n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwrh7zIwZVci",
        "outputId": "59955005-0b39-4a39-d10f-b5775ab4ef3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "for epoch in range(3):\n",
        "  running_loss = 0.0\n",
        "  for images, labels in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rgkoKBpZbcP",
        "outputId": "94df1d20-3656-473d-bb2b-d2698302dc75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.15834453227375744\n",
            "Epoch 2, Loss: 0.04621030425298899\n",
            "Epoch 3, Loss: 0.031998246441595754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Performance\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in testloader:\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_ckCKCSadZ8",
        "outputId": "70b2c57e-1fcc-497e-86cd-b78aac26f8ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Prediction & Explainability with Gemini API"
      ],
      "metadata": {
        "id": "mjaMD_97bnje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a Prediction on an Image\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "index = random.randint(0, len(images) - 1)\n",
        "img = images[index].squeeze()\n",
        "true_label = labels[index].item()\n",
        "output = model(images[index].unsqueeze(0))\n",
        "predicted_label = torch.argmax(output).item()\n",
        "plt.imshow(img.numpy(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted_label}, True: {true_label}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Mltth1ISbNvR",
        "outputId": "8c9cbfb9-9e53-4774-9c5c-14da8db4bea9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect with Gemini API for Explainability\n",
        "\n",
        "import requests\n",
        "\n",
        "GEMINI_API_KEY = \"AIzaSyAHVjHWz9HcKqOpXiJnrOlVIQ16JazuK84\"\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\" # Correct endpoint for generateContent\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "predicted_label = 5  # Example: Replace with the actual predicted label from your CNN model\n",
        "\n",
        "prompt_text = f\"The CNN model predicted digit {predicted_label} for an image. Explain why it might have made this prediction.\"\n",
        "\n",
        "data = {\n",
        "    \"contents\": [{  # Use \"contents\" which is an array\n",
        "        \"parts\": [{\"text\": prompt_text}] # Parts is also an array, containing text\n",
        "    }],\n",
        "    \"generationConfig\": { # Optional generation config for temperature and candidate count\n",
        "        \"temperature\": 0.7,\n",
        "        \"candidateCount\": 1\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(f\"{GEMINI_ENDPOINT}?key={GEMINI_API_KEY}\", headers=headers, json=data)\n",
        "response.raise_for_status() # Good practice to check for HTTP errors\n",
        "\n",
        "response_json = response.json()\n",
        "\n",
        "# Correctly access the explanation from the JSON response\n",
        "if 'candidates' in response_json and response_json['candidates']:\n",
        "    candidate = response_json['candidates'][0]\n",
        "    if 'content' in candidate and candidate['content']['parts']:\n",
        "        explanation = candidate['content']['parts'][0].get('text', 'No explanation found') # Safely get text, default if not found\n",
        "        print(\"Gemini Explanation:\", explanation)\n",
        "    else:\n",
        "        print(\"Error: No 'content' or 'parts' found in the candidate response.\")\n",
        "else:\n",
        "    print(\"Error: No 'candidates' found in the response.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1rYLUS_b2B0",
        "outputId": "76fcf419-1db5-45b0-cf22-612b282a9387"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Explanation: **Possible Reasons for the CNN Model Predicting Digit 5:**\n",
            "\n",
            "**1. Similar Features:**\n",
            "* The image may have contained features that are commonly associated with the digit 5, such as a curved top, a vertical line in the middle, and a hook on the bottom.\n",
            "\n",
            "**2. Overfitting:**\n",
            "* The CNN model might have been overfitted to the training data, where it learned specific patterns that are not generalizable to unseen data. As a result, it may have incorrectly classified the image as 5 even though it does not strongly resemble that digit.\n",
            "\n",
            "**3. Noise or Distortions:**\n",
            "* The image may have contained noise or distortions that altered its appearance, making it more similar to the digit 5 than its true label.\n",
            "\n",
            "**4. Limited Training Data:**\n",
            "* If the CNN model was trained on a limited dataset, it may not have encountered enough variations of the true digit to accurately classify it.\n",
            "\n",
            "**5. Occlusions or Missing Features:**\n",
            "* The image may have contained occlusions or missing features that made it difficult for the model to accurately determine its true identity.\n",
            "\n",
            "**6. Poor Image Quality:**\n",
            "* If the image was of poor quality, such as blurry or pixelated, it could have hindered the model's ability to extract meaningful features.\n",
            "\n",
            "**7. Class Imbalance:**\n",
            "* If the training dataset had an imbalance between the digit 5 and other digits, the model may have been biased towards predicting 5, even if the image was not a true representation of that digit.\n",
            "\n",
            "**8. Architectural Limitations:**\n",
            "* The CNN model's architecture may not have been complex enough to capture the subtle differences between the digit 5 and other similar digits.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Task"
      ],
      "metadata": {
        "id": "FfTKayuAfxpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Ensure images are loaded as 3-channel RGB\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),   # Resize to 32x32 (CIFAR-10 size)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize between -1 and 1\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGoC06djkp1X",
        "outputId": "29ddcebd-60b5-40d5-ffa2-8a27fb514d96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modify CNN to Handle CIFAR-10\n",
        "\n",
        "class CIFARCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CIFARCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "  def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))\n",
        "    x = self.pool(torch.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 32 * 8 * 8)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "model_cifar = CIFARCNN()"
      ],
      "metadata": {
        "id": "mCUSP6j0frk_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model & Move to GPU (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CIFARCNN().to(device)\n",
        "\n",
        "# Define Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "_F1PoNFQg0Zx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model for 2 Epochs\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GqboZ_BiR3M",
        "outputId": "3f7b6236-f33a-42af-af7d-66f0e4de7425"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Loss: 1.4351\n",
            "Epoch 2/2, Loss: 1.0770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESj6AGheY9Xr",
        "outputId": "85cbabbd-1e61-44f3-fdc0-32fba3f0feb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 64.42%\n"
          ]
        }
      ]
    }
  ]
}